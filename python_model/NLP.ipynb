{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f83edb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонки у файлі: ['автор', 'нація', 'рахунок', 'назва', 'Позитивні відгуки', 'Негативні відгуки', 'Дата коментаря', 'Тип кімнати', 'Дата заїзду', 'Дата виїзду']\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 11s 192ms/step - loss: 0.6794 - acc: 0.6240 - val_loss: 0.9567 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.6582 - acc: 0.6250 - val_loss: 0.9920 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.6482 - acc: 0.6260 - val_loss: 1.1999 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.6232 - acc: 0.6732 - val_loss: 1.2839 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.5755 - acc: 0.7185 - val_loss: 0.7807 - val_acc: 0.0000e+00\n",
      "\n",
      "✅ Модель успішно навчена і збережена!\n"
     ]
    }
   ],
   "source": [
    "# Імпортувати необхідні бібліотеки\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import joblib\n",
    "\n",
    "# === 1. Завантажити набір даних ===\n",
    "data = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "print(\"Колонки у файлі:\", data.columns.tolist())\n",
    "\n",
    "# === 2. Формування корпусу текстів і міток ===\n",
    "# Об’єднуємо позитивні та негативні відгуки в один набір\n",
    "pos = data['Позитивні відгуки'].fillna(\"\").astype(str)\n",
    "neg = data['Негативні відгуки'].fillna(\"\").astype(str)\n",
    "\n",
    "# Створюємо текстовий корпус (всі відгуки)\n",
    "x = pd.concat([pos, neg], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Створюємо мітки: 1 — позитивний, 0 — негативний\n",
    "y = np.array(['positive'] * len(pos) + ['negative'] * len(neg))\n",
    "\n",
    "# Якщо потрібно обмежити до 2500 записів:\n",
    "x = x[:2500]\n",
    "y = y[:2500]\n",
    "\n",
    "# === 3. Токенізація ===\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(x)\n",
    "sequences = tokenizer.texts_to_sequences(x)\n",
    "maxlen = 50\n",
    "x = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "# === 4. Кодування міток ===\n",
    "binr = OneHotEncoder(sparse_output=False)\n",
    "y = binr.fit_transform(np.array(y).reshape(-1, 1))\n",
    "\n",
    "# === 5. Побудова моделі ===\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=1000, output_dim=16))\n",
    "model.add(Bidirectional(LSTM(16, return_sequences=True)))\n",
    "model.add(LSTM(16, return_sequences=True))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# === 6. Компіляція ===\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "# === 7. Навчання ===\n",
    "history = model.fit(x, y, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# === 8. Збереження ===\n",
    "model.save('sentiment_analysis_model.h5')\n",
    "joblib.dump(tokenizer, 'tokenizer.joblib')\n",
    "joblib.dump(binr, 'encoder.joblib')\n",
    "\n",
    "print(\"\\n✅ Модель успішно навчена і збережена!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9489c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# views.py\n",
    "from django.shortcuts import render\n",
    "from django.http import HttpResponse\n",
    "import joblib\n",
    "\n",
    "def sentiment_analysis_view(request):\n",
    "    if request.method == 'POST':\n",
    "        # Get the user input\n",
    "        text = request.POST['text']\n",
    "\n",
    "        # Load the saved NLP model\n",
    "        model = joblib.load('sentiment_analysis_model.joblib')\n",
    "\n",
    "        # Perform the prediction\n",
    "        prediction = model.predict([text])[0]\n",
    "\n",
    "        # Render the template with the prediction result\n",
    "        return render(request, 'sentiment_analysis.html', {'prediction': prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "814a7e0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11144\\541688085.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# urls.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdjango\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murls\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mviews\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msentiment_analysis_view\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m urlpatterns = [\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "# urls.py\n",
    "from django.urls import path\n",
    "from .views import sentiment_analysis_view\n",
    "\n",
    "urlpatterns = [\n",
    "    path('sentiment/', sentiment_analysis_view, name='sentiment_analysis'),\n",
    "    # Add other URL patterns as needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaedaca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
